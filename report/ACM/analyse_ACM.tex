\documentclass[]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{hyperref}
\usepackage[russian]{babel}
\usepackage[figwhole,footnotes,oglav,spisok,boldsect,eqwhole,kursrab,remarks,hyperprint]
{project}
\usepackage{hhline}

% Copyright
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}
\settopmatter{printacmref=false}


\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\pagestyle{plain} % removes running headers

\begin{document}
\title{Отчет}


\author{Чернов Андрей}
\email{chernov.andrey.98@mail.ru}
% The default list of authors is too long for headers.
%\renewcommand{\shortauthors}{}


%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%




\maketitle

\section{Отбор признаков}


\begin{enumerate}
  \item 
  Я посчитал выборочную дисперсию всех признаков и сразу удалил признак, у которого дисперсия оказалась равной нулю.  
  \item
  Я отделил бинарные признаки от количественных, для количественных признаков и $y$ построил boxplot( рис. \ref{boxFeat} по оси абсцисс номер признака, по оси ординат значения, последний  - это $y$). Оказалось, что у очень многих признаков мало ненулевых значений, я удалил признак, у которого только два ненулевых значения(десятый признак), хотя, конечно, в данном месте желательно провести дополнительный анализ и понять какие из разреженных признаков нужны, а какие нет. Также удалил три образца, которые соответствуют трем экстремальным значениям $y$. Далее я отбирал признаки двумя разными способами.   
  \item Первый способ - это корреляционный анализ. С помощью теста Спирмена я построил корреляционную матрицу и посчитал p-value. Я отбирал количественные признаки таким образом, чтобы значение p-value между признаками, присутсвутющими в выборке не было меньше, чем $1e-05$. Бинарные признаки я не трогал. Я оставил 18 признаков.
  \item Второй способ - это посчитать information gain( mutual information) между каждым признаком и $y$, при это я не стал убирать бинарные признаки. Таким образом, я оставил 23 наиболее информативных признаков.
\end{enumerate}

\figbox{15cm}{15cm}{boxplotFeatures.pdf}{boxFeat}{}

\section{Выбор модели}
Для начала я решил попробовать обычную линеную регрессию, чтобы получить базовые результаты. Несмотря на то, что данных и признаков не очень много я решил попробовать полносвязную нейронную сеть на полном наборе признаков(исключая только константные) с функцией активации: RELU и l1 регуляризацией. Моя идея была в том, что l1 регуляризация и RELU могут занулить веса неинформативных признаков. К сожалению, у меня не получилось заставить работать l1 регуляризацию и я ее убрал с конечной модели. Сама модель состоит из трех полносвязных словев с параметрами 32, 16 и 1 соответсвенно. Также я применил градиентный бустинг над решающими деревьями( использовал библиотеку XGBoost).

\section{Результаты}
Для оценки результатов, я обучал модели 20 раз, каждый раз перемешивая датасет. В качестве тренировочных данных я брал $500$ образцов, а остальные $105$ использовал в качестве тестовых данных. Data0 - это датасет со всем признаками, исключая константные. Data1 - это датасет с признаками, отобранными корреляционным анализом. Data2 - это датасет с признаками, отобранными с помощью gain infromation. В качестве метрик качества я использовал: mae и $R^{2}$. На вход полносвязной сети я подавал только Data0.
Для линейной регрессии:\\
\begin{center}
	\begin{tabular}{|l|l|l|l|}
		\hhline{|~|-|-|-|}
		\multicolumn{1}{c|}{}&\multicolumn{3}{c|}{Метрики}\\
		\hline	
		& mae train  & mae test & $R^{2}$    \\	
		\hline
		Data0 & 0.032 &0.032& 0.57 \\
		\hline
		Data1 &0.035& 0.036 & 0.51 \\
		\hline
		Data2 &0.032& 0.033 & 0.59 \\
		\hline
	\end{tabular}
\end{center}
Для бустинга:\\
\begin{center}
	\begin{tabular}{|l|l|l|l|}
		\hhline{|~|-|-|-|}
		\multicolumn{1}{c|}{}&\multicolumn{3}{c|}{Метрики}\\
		\hline	
		& mae train  & mae test & $R^{2}$    \\	
		\hline
		Data0 & 0.032 &0.034& 0.57 \\
		\hline
		Data1 &0.0219&0.0064 & 1.15e-3 \\
		\hline
		Data2 &0.0219&0.0064 & 1.15e-3 \\
		\hline
	\end{tabular}
\end{center}



Для полносвязной сети:\\	
\begin{center}
	\begin{tabular}{|l|l|l|l|}
		\hhline{|~|-|-|-|}
		\multicolumn{1}{c|}{}&\multicolumn{3}{c|}{Метрики}\\
		\hline	
		& mae train  & mae test & $R^{2}$    \\
		\hline	
		Data0 & 0.025 &0.031& 0.62 \\
		\hline
	\end{tabular}

\end{center}

Судя по результатам, я не совсем эффективно отобрал признаки. Некоторые из гиперпараметров я брал по умолчанию, какие-то настраивал вручную.

\end{document}
